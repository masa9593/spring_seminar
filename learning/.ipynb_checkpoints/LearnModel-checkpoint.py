# -*- coding: utf-8 -*-
"""LearnModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CrFdpaVps_iqrlpdBQGR-oXYFphTDx7v
"""

import torch.optim as optimizer
import torch
import numpy as np

def train(model, train_dataloader, optimizer, criterion, device):
    model.train()
    running_loss = 0
    correct = 0
    total = 0
    
    for dataset in train_dataloader:
        image = dataset['image'].to(torch.float).to(device)
        target = dataset['target'].to(torch.long).to(device)
        
        optimizer.zero_grad()
        
        outputs = model(image)
        
        '''
        del image
        torch.cuda.empty_cache()
        '''
        
        loss = criterion(outputs, target)
        
        
        loss.backward()
        optimizer.step()
        
        
        running_loss += loss.item()
        _, predicted = outputs.max(1)
        correct += (predicted == target).sum().item()
        total += target.size(0)
        
        '''
        del target
        torch.cuda.empty_cache()
        '''
        
        
        '''
        del loss
        torch.cuda.empty_cache()
        '''
        
        
    train_loss = running_loss / len(train_dataloader) 
    train_acc = correct / total
    
    return train_loss, train_acc

def valid(model, valid_dataloader, criterion, device, is_test=False):
    model.eval()
    running_loss = 0
    correct = 0
    total = 0
    Correct_Data = []
    False_Data = []
    with torch.no_grad():
        for dataset in valid_dataloader:
            image = dataset['image'].to(torch.float).to(device)
            target = dataset['target'].to(torch.long).to(device)
            
            outputs = model(image)
            
            loss = criterion(outputs, target)
            
            running_loss += loss.item()
            _, predicted = outputs.max(1)
            correct += (predicted == target).sum().item()
            total += target.size(0)
            
            if is_test:
                for i, bool_ in enumerate(predicted == target):
                    if bool_:
                        Correct_Data.append(dataset['original_image'][i].numpy())
                    else:
                        False_Data.append(dataset['original_image'][i].numpy())
                    
                print(f'correct: {predicted==target}, target: {target}, pred: {predicted}')
                print(f'outputs: {outputs}')
                print(f'loss: {loss}, running_loss: {running_loss}')
                print(f'total correct: {correct}, total: {total}')
            
        val_loss = running_loss / len(valid_dataloader)
        val_acc = correct / total
        
        return val_loss, val_acc, Correct_Data, False_Data

def Learn_Model(train_dataloader, valid_dataloader, model, num_of_epoch, criterion, optimizer, device):
    train_loss_list = []
    train_acc_list = []
    valid_loss_list = []
    valid_acc_list = []
    
    '''学習'''
    for epoch in range(num_of_epoch):
        disp_epoch = int(num_of_epoch // 5)
        if disp_epoch == 0:
            disp_epoch = 1
        
        train_loss, train_acc = train(model, train_dataloader, optimizer, criterion, device)
        val_loss, val_acc, _, _ = valid(model, valid_dataloader, criterion, device, is_test=False)
        
        if (epoch + 1) % disp_epoch == 0:
            print('epoch %d, train loss: %.4f , train_acc: %.4f, val_loss: %.4f val_acc: %.4f' % (epoch, train_loss, train_acc, val_loss, val_acc))
            
        train_loss_list.append(train_loss)
        train_acc_list.append(train_acc)
        valid_loss_list.append(val_loss)
        valid_acc_list.append(val_acc)
        
    result = {'train':
              {'loss': train_loss_list, 
               'acc': train_acc_list}, 
              'test':
              {'loss': valid_loss_list, 
               'acc': valid_acc_list}
             }
    return model, result

if __name__ == '__main__':
    import matplotlib.pyplot as plt
    from torch.utils.data import DataLoader, Dataset
    import torch.nn as nn
    from MNISTDataset import Make_Datasetfrom, Network 
    import Choice_Model
    target_class = [0, 1, 2]
    num_of_img_per_class = 100
    train_dataset, valid_dataset, test_dataset = Make_Dataset(target_class, num_of_img_per_class)
    train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)
    valid_dataloader = DataLoader(valid_dataset, batch_size=4, shuffle=True)
    model_name = 'sample_CNN'
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(device)
    model = Choice_Model(model_name, target_class).double().to(device)
    print(model)

if __name__ == '__main__':
    num_of_epoch = 10
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)
    
    model, result = Learn_Model(train_dataloader, valid_dataloader, model, num_of_epoch, criterion, optimizer)
    
    x = np.arange(num_of_epoch)
    
    plt.subplot(1, 2, 1, title='Loss')
    plt.plot(x, result['train']['loss'], color='red', label='train')
    plt.plot(x, result['valid']['loss'], color='blue', label='valid')
    
    plt.subplot(1, 2, 2, title='Acc')
    plt.plot(x, result['train']['acc'], color='red', label='train')
    plt.plot(x, result['valid']['acc'], color='blue', label='valid')