{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d1ef03d-a670-480d-b7da-1fef2a918aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-07 11:54:12.251659: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "from random import seed\n",
    "from tools import hio, util\n",
    "from learning.LearnModel import Learn_Model, valid\n",
    "from models.ChoiceModel import Choice_Model\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "conf = util.parse_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61682c06-4d70-4b57-a93e-78a75c0d0d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image data\n",
    "random_state = 10\n",
    "DEFAULT_HEIGHT = 64\n",
    "n_components = 64 * 6\n",
    "\n",
    "#target data\n",
    "Class = {\n",
    "    'Malignant' : 0,\n",
    "    'Benign' : 1\n",
    "}\n",
    "\n",
    "# learning setting\n",
    "# model_name = 'vggLike_3DCNN'\n",
    "# model_name = 'ResNetLike_3DCNN'\n",
    "model_name = 'my_3DCNN'\n",
    "# model_name = 'sample_3DCNN'\n",
    "\n",
    "batch_size = 4\n",
    "learningRate = 0.001\n",
    "num_of_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98327a75-d787-4c19-8f4e-e08041994ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train IDs: ['321' '230' '157' '160' '233' '342' '251' '236' '308' '163' '348' '199'\n",
      " '290' '227' '333' '361' '215' '324' '263' '266' '150' '260' '181' '218'], test IDs: ['212' '187' '284']\n",
      "image data size (317, 64, 64, 401)\n",
      "label size (317,)\n",
      "xtrain:  317 , xtest:  20 ytrain:  317 , ytest:  20\n",
      "[0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "231 86\n",
      "11 9\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = hio.get_train_test_for_clasification(Class, height=DEFAULT_HEIGHT, n_components=n_components, is_split=True, show_image=True, random_state=random_state)\n",
    "\n",
    "print(y_train)\n",
    "print(y_test)\n",
    "print(sum(y_train==0), sum(y_train==1))\n",
    "print(sum(y_test==0), sum(y_test==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80a606b3-fa65-4ed5-8d40-63c139e9fe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class medHSI_Dataset(Dataset):\n",
    "    def __init__(self, images, targets, transform, n_components=10):\n",
    "        self.images = images\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "        self.n_components = n_components\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        original_image = self.images[index]\n",
    "        image = self.transform(original_image)\n",
    "        image = self.decompose(image, n_components=self.n_components)\n",
    "        image = image.view(1, image.size(0),image.size(1),image.size(2))\n",
    "        \n",
    "        target = self.targets[index]\n",
    "        \n",
    "        dataset = {'image': image, 'target': target, 'original_image': original_image}\n",
    "        \n",
    "        return dataset\n",
    "        \n",
    "    def show_montage_dataset(self, channel=401, name='train'):\n",
    "        from tools import util\n",
    "        util.show_montage(self.images, channel=channel, savename=name+'_montage.jpg')\n",
    "    \n",
    "    def decompose(self, hsi, n_components=10):\n",
    "        numDecom = hsi.shape[0] - n_components\n",
    "        decom_hsi = hsi[numDecom//2:numDecom//2+n_components, :, :]\n",
    "        \n",
    "        return decom_hsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2c2d5b5-364a-4cdf-943b-e3f60b0a31c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class = list(Class.values())\n",
    "\n",
    "originalTransform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(tuple(util.Average_for_hsiList(x_train)), tuple(util.Std_for_hsiList(x_train)))])\n",
    "\n",
    "train_dataset = medHSI_Dataset(x_train, y_train, transform=originalTransform, n_components=n_components)\n",
    "train_dataset.show_montage_dataset(channel=401, name='train')\n",
    "test_dataset = medHSI_Dataset(x_test, y_test, transform=originalTransform, n_components=n_components)\n",
    "test_dataset.show_montage_dataset(channel=401, name='test')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3fbfe58-31a4-4566-b264-507cc6e29004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f506d6b-00aa-454b-8067-3f210563a54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 0.6337 , train_acc: 0.6972, val_loss: 0.7221 val_acc: 0.5500\n",
      "epoch 0, train loss: 0.6217 , train_acc: 0.7098, val_loss: 0.7339 val_acc: 0.5500\n",
      "epoch 0, train loss: 0.6119 , train_acc: 0.6909, val_loss: 0.8991 val_acc: 0.5500\n",
      "epoch 0, train loss: 0.6048 , train_acc: 0.7161, val_loss: 0.8275 val_acc: 0.5500\n"
     ]
    }
   ],
   "source": [
    "n = 1\n",
    "\n",
    "r = []\n",
    "\n",
    "for i in range(n):\n",
    "    model = Choice_Model(model_name, train_dataset[0]['image'], target_class).to(torch.float).to(device)\n",
    "    if device == 'cuda':\n",
    "        model = torch.nn.DataParallel(model) # make parallel\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(params=model.parameters(), lr=learningRate, momentum=0.9)\n",
    "    \n",
    "    model, result = Learn_Model(train_dataloader, test_dataloader, model, num_of_epoch, criterion, optimizer, device)\n",
    "    \n",
    "    r.append([result['train']['loss'][-1], result['train']['acc'][-1], result['test']['loss'][-1], result['test']['acc'][-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938ac5d4-d234-4929-90b0-28f9f5811c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n):\n",
    "    print(r[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99436bed-6039-4ecb-b3e0-fe249e0987d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4ad4aa-6006-44ff-9b1e-7d63ea121e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74def27e-01ba-4d71-8a22-7df7b497ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loss, train_acc, train_Correct_Data, train_False_Data = valid(model, train_dataloader, criterion, device, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c417e0ac-9caa-462d-bdd5-6b6a15490389",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print(len(train_Correct_Data))\n",
    "if len(train_Correct_Data) != 0:\n",
    "    print(train_Correct_Data[0].shape)\n",
    "    \n",
    "print(len(train_False_Data))\n",
    "if len(train_False_Data) != 0:\n",
    "    print(train_False_Data[0].shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a676f2a6-1afc-4b48-bd69-21432bec4143",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "if len(train_Correct_Data) != 0:\n",
    "    util.show_montage(train_Correct_Data, channel=401, savename='train_Correct_Data_montage.jpg')\n",
    "\n",
    "if len(train_False_Data) != 0:\n",
    "    util.show_montage(train_False_Data, channel=401, savename='train_False_Data_montage.jpg')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff2f99f-74b0-4cc9-a242-22b3ebe99799",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc, Correct_Data, False_Data = valid(model, test_dataloader, criterion, device, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ef5661-8003-451f-a414-7cd3566799ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Correct_Data))\n",
    "if len(Correct_Data) != 0:\n",
    "    print(Correct_Data[0].shape)\n",
    "    \n",
    "print(len(False_Data))\n",
    "if len(False_Data) != 0:\n",
    "    print(False_Data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fb1d73-adcc-4ec1-9d15-fb105a08188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(Correct_Data) != 0:\n",
    "    util.show_montage(Correct_Data, channel=401, savename='Correct_Data_montage.jpg')\n",
    "\n",
    "if len(False_Data) != 0:\n",
    "    util.show_montage(False_Data, channel=401, savename='False_Data_montage.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8dbc4c-5114-4535-bfc5-21174eac25f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(num_of_epoch)\n",
    "\n",
    "loss_max = max(max(result['train']['loss'], result['test']['loss'], key=max))\n",
    "\n",
    "plt.subplot(1, 2, 1, title='Loss')\n",
    "plt.plot(x, result['train']['loss'], color='red', label='train')\n",
    "plt.plot(x, result['test']['loss'], color='blue', label='test')\n",
    "plt.ylim(0, loss_max+0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2, title='Acc')\n",
    "plt.plot(x, result['train']['acc'], color='red', label='train')\n",
    "plt.plot(x, result['test']['acc'], color='blue', label='test')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "filename = os.path.join(conf['Directories']['outputDir'], 'T20211207-python', '学習曲線.png')\n",
    "plt.savefig(filename)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84df4c8d-e122-4305-915c-e2d8a7f8d8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model=model, input_size=(batch_size, 1, n_components, DEFAULT_HEIGHT, DEFAULT_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c396fe1f-617b-451c-b19d-150121eb1fde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
